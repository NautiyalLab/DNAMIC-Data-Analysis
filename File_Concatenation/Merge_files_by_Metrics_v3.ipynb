{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Partial String Match (using 'in')- SO](https://stackoverflow.com/questions/14849293/python-find-index-position-in-list-based-of-partial-string)\n",
    "\n",
    "[Multiple Keys to a single value](https://stackoverflow.com/questions/1921027/python-many-to-one-mapping-creating-equivalence-classes0)  \n",
    "[Multiple Keys to a single value - Class method](https://stackoverflow.com/questions/11105115/data-structure-to-implement-a-dictionary-with-multiple-indexes/11105962#11105962)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from natsort import natsorted, ns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jhl/Documents/Nautiyal Lab/ARDUINO FINAL 0904/Group 2/TEST_folder'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all the dataframes into a single dataframe\n",
    "\n",
    "Input: csv file of the daily metrics (total pokes / delay window / omission trials etc.)  \n",
    "Output: single metric indexed by dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = cwd + \"/*.csv\"\n",
    "\n",
    "df_list = []\n",
    "for fname in natsorted(glob.glob(path), alg=ns.IGNORECASE):\n",
    "    \n",
    "    df = pd.read_csv(fname, header=[0,1], index_col=0, dtype='object', low_memory=False)  # read in multi-index dataframe\n",
    "    df_list.append(df)\n",
    "    \n",
    "combined_df = pd.concat(df_list, axis=0)   # concat vertically! axis=0 --> along columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idx = combined_df.index.tolist()\n",
    "# df_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionay of of string (keys) to code (value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dict = { \n",
    "    ('delay_window','dw','pokes_delay_window'): 'oo59', \n",
    "    ('iti_window', 'iti', 'pokes_iti_window') : 'oo19',\n",
    "    ('trial_window', 'tw', 'pokes_trial_window') : 'oo29',\n",
    "    ('paradigm_total', 'total_pokes', 'pokes_paradigm_total') : 'x071',\n",
    "    ('omission', 'trials_omission') : 'x540',\n",
    "    ('incorrect', 'trials_incorrect') : 'x160',\n",
    "    ('reward', 'trials_reward') : 'x271',\n",
    "    ('initiated', 'trials_initiated') : 'x171'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[dict.items() - Looping Techniques](https://docs.python.org/3/tutorial/datastructures.html)\n",
    "\n",
    "[dict.items() - returns key,value tuple pair](https://www.tutorialspoint.com/python3/dictionary_items.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_code_dict = {}\n",
    "for k, v in code_dict.items():\n",
    "    for key in k:\n",
    "        working_code_dict[key] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delay_window': 'oo59',\n",
       " 'dw': 'oo59',\n",
       " 'pokes_delay_window': 'oo59',\n",
       " 'iti_window': 'oo19',\n",
       " 'iti': 'oo19',\n",
       " 'pokes_iti_window': 'oo19',\n",
       " 'trial_window': 'oo29',\n",
       " 'tw': 'oo29',\n",
       " 'pokes_trial_window': 'oo29',\n",
       " 'paradigm_total': 'x071',\n",
       " 'total_pokes': 'x071',\n",
       " 'pokes_paradigm_total': 'x071',\n",
       " 'omission': 'x540',\n",
       " 'trials_omission': 'x540',\n",
       " 'incorrect': 'x160',\n",
       " 'trials_incorrect': 'x160',\n",
       " 'reward': 'x271',\n",
       " 'trials_reward': 'x271',\n",
       " 'initiated': 'x171',\n",
       " 'trials_initiated': 'x171'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_metrics_code(metric_string):\n",
    "    return working_code_dict[metric_string]\n",
    "\n",
    "## Later make error checks!! (KeyError / ValueError etc.- using instance checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pokes_paradigm_total'\n",
    "code = return_metrics_code(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_idx = [i for i, s in enumerate(df_idx) if code in s]\n",
    "final_metric_csv = combined_df.iloc[metric_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metric_csv.to_csv(filename + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type this in \"pandas read csv read all files in folder\" to google to get following results:   \n",
    "[Read THIS! Stack Overflow - Starting Point](https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe)  \n",
    "[Jonathan Soma Blog](http://jonathansoma.com/lede/foundations-2017/classes/working-with-many-files/class/)  \n",
    "[Medium Post - Not as Useful but still...](https://medium.com/@kadek/elegantly-reading-multiple-csvs-into-pandas-e1a76843b688)\n",
    "\n",
    "[Maybe helpful?](https://www.techbeamers.com/pandas-merge-csv-files/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to Ask Jinhyeon Hyung\n",
    "\n",
    "**1. Regarding Latency Plot**\n",
    "- how to get a certain pair WITHOUT using for loops (I think similar approach was used last time with MATLAB)\n",
    "- example: STARTING POINT: end of reward (8270)  ENDING POINT: trial window counter (7519) \n",
    "- once i have that parsed index, I can get the FIRST poke in (8071) BETWEEN those indexes\n",
    "\n",
    "- Currently I return the retrieval index based on the FIRST poke after reward index (using np.where boolean evaluations) \n",
    "- But this case would probably silenty fail, if the mouse didnt retrieve the reward before the next trial started. \n",
    "\n",
    "- Having this START POINT and END POINT will allow for better data integrity / consistency since the POKE IN can only occur at a specified / given timeframe\n",
    "\n",
    "\n",
    "\n",
    "**2. Regarding merging csv files**\n",
    "- (how to read in multiple (all) files within the directory and output csv file accoridng to certain values)\n",
    "- in my case, based on a certain code  (concatenate only the same codes and output the dataframe into a new csv file)\n",
    "- and then call custom plotting function on that csv file!! (final workflow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pandas Merging 101](https://stackoverflow.com/questions/53645882/pandas-merging-101?answertab=votes#tab-top)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
